{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем данные из 'ruwiki-latest-abstract.xml' и разбиваем на строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ruwiki-latest-abstract.xml', encoding= 'utf-8') as file:\n",
    "    file_row = [row.strip() for row in file]\n",
    "file_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проходим по строкам и выбираем только ссылки\n",
    "Сохраняем в массив urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "urls = []\n",
    "for row in file_row:\n",
    "    if \"<url>\" in row:\n",
    "        urls.append(row[5:-6])\n",
    "        \n",
    "urls   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переходим на страницу википедии по каждой ссылке, проверяем есть ли идентификатор \"DrugBank\" в инфобоксе (или в одном из инфобоксов, если их несколько)\n",
    "Подходящие статьи записываем в файл 'DrugBank_article.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocess\n",
    "import requests\n",
    "\n",
    "def my_f(url):\n",
    "    import requests\n",
    "    import string\n",
    "    from bs4 import BeautifulSoup\n",
    "    req = requests.get(url) \n",
    "    soup = BeautifulSoup(req.text)\n",
    "    all_infobox = soup.findAll(\"table\", {\"class\": \"infobox\"})\n",
    "    for i in all_infobox:\n",
    "        if \"DrugBank\" in i.text:\n",
    "            if i.find(\"a\", href= re.compile('h*//www.drugbank.ca/*')).string != \"none\" and i.find(\"a\", href= re.compile('h*//www.drugbank.ca/*')) != \"?\":\n",
    "                with open('DrugBank_article.txt', 'a', encoding = \"utf-8\") as filehandle:  \n",
    "                    filehandle.write('%s\\n' % req.text)\n",
    "        break\n",
    "        \n",
    "for i in urls:\n",
    "        p = multiprocess.Process(target=my_f, args=(i, ))\n",
    "        p.start()\n",
    "\n",
    "print(\"end\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем статьи из файла 'DrugBank_article.txt', записываем в массив drug_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandle = open('DrugBank_article.txt', 'r', encoding=\"utf-8\").read() \n",
    "drug_article = filehandle.split(\"<!DOCTYPE html>\")\n",
    "drug_article=drug_article[1::]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Длина массива drug_article (=942)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "942"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(drug_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проходим по статьям из drug_article и формируем строку таблицы str \n",
    "Строку записываем в файл 'drugBank_table.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in drug_article:\n",
    "    soup = BeautifulSoup(article)\n",
    "    all_infobox = soup.findAll(\"table\", {\"class\": \"infobox\"})\n",
    "    for i in all_infobox:\n",
    "        if \"DrugBank\" in i.text:\n",
    "            infobox = i\n",
    "    name = soup.find(\"h1\", id=\"firstHeading\").string\n",
    "    if name is None:\n",
    "        name = infobox.find(\"th\", {\"class\":\"infobox-above\"}).string\n",
    "    str = \"\"\n",
    "    str = str + soup.find(\"link\", {\"rel\": \"canonical\"})[\"href\"] + \"\\\\t\" + name + \"\\\\t\" + infobox.find(\"a\", href= re.compile('h*//www.drugbank.ca/*')).string + \"\\\\t\" + infobox.find(\"a\", href= re.compile('h*://www.drugbank.ca/*'))[\"href\"] \n",
    "    if \"Другие названия\" in infobox.text:\n",
    "        str = str + \"\\\\t\" + infobox.findAll(\"td\", {\"class\": \"plainlist\"})[-1].text[1::].replace(\"\\n\", \" \")\n",
    "    with open('drugBank_table.txt', 'a', encoding=\"utf-8\") as filehandle:  \n",
    "        filehandle.write('%s\\n' % str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
